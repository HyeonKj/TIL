=====================================
2022- 03 -14
**[ProDS] 데이터 분석 이론 (초급+중급)**
학습 목차
# 22차시 데이터 전처리 
=====================================

# 데이터 정제 

## 결측값의 이해 
### 기록 누락, 미응답, 수집오류 등의 이유로 결측이 발생, 결측값이 포함된 자료라도 나머지 변수의 값들은 의미 있는 정보이므로, 정보의 손실을 최소화하도록 결측을 처리하는 것이 바람직함. 


## 데이터 결측값 처리법

### 완전 제거법 
- 결측값이 하나 이상 포함된 자료를 제거하는 방법. 
- 정보의 손실로 분석 결과가 왜곡이 될 수 있음.

### 평균 대체법
- 결측값을 해당 변수의 나머지 값들의 평균으로 대체하는 방법.
- 추정량의 표준오차가 과소추정되는 문제가 있음 


### 핫덱대체법 
- 동일한 데이터 내에서 결측값이 발생한 관찰치와 유사한 특성을 가진 다른 관찰치의 정보를 이용하여 대체하는 방법.

### 그 밖의 결측값 처리법
- Regression imputation, KNN imputation 등. 

### 이상값의 이해 
- 이상값은 다른 데이터와 동떨어진 것을 말함. 
- 다른 자료값들에 비해 멀리 떨어져 있지만 의미가 있는 값일 수도 있고, 단순히 입력 오류로 발생한 값일 수도 있음.

###  연속형 자료의 범주화
- 변수 구간화의 효과
- 이상치 문제를 완화, 
- 결측치 처리 방법이 될 수 있음
- 변수 간 관계가 단순화 되어 분석 시 과적합을 방지할 수 있고, 결과 해석이 용이해짐.

## 데이터 전처리 과정 : 데이터의 정보를 어떻게 하면 잘 살리면서 분석에 용이한 형태로 만들 수 있을까? 
# 실제 분석에 들어가는 소요시간보다 훨씬 많은 시간을 들여 노력하는 과정이다. 

================================


# 데이터 변환 
- 자료 변환을 통해 자료의 해석을 쉽고 풍부하게 하기 위한 과정.

### 데이터 변환 목적 
- **분포의 대칭화.**
- **산포를 비슷하게 하기 위하여.**
- **변수 간 관계를 단순하게 하기 위하여.**

### 변환 유형 1: 제곱 변환 vs 제곱근 변환
### 변환 유형 2: 로그 변환 vs 지수 변환
### 박스콕스 변환 (BOX-COX TRANSFROM)
### : 제곱근 유형의 변환을 일반화, vs 제곱 유형의 변환을 일반화, 지수 변환 x의 p승 


## 데이터 결합
### 이너조인 :
- 두 테이블에 키가 공통으로 존재하는 레코드만 결합.
- (A, 1, T), (B, 2, F)
- : A:1, B:2
### 풀아우터조인(full)
- 두 테이블 중 어느 한 쪽이라도 존재하는 키에 대한 레코드를 모두 결합.
- (A, 1, T),(B, 2, F),(C, 3, NA), (D, NA, T)


# 데이터 변환
이너조인
크로스 조인
라이트조인
레프트조인

========================
# 23차시 머신러닝의 기본 개념 및 방법론의 분류
==========================

**최근 머신러닝의 활용 증가**
- 컴퓨팅 성능 발전 / 머신러닝 알고리즘 발전/ 대용량 데이터 축적 및 관리기술의 발전이 **배경**

### 지도학습
* 라벨이 있는 훈련용 데이터에서 여러 특성변수를 이용하여 목표변수인 라벨을 예측하도록 모델을 학습함.
- 라벨의 데이터 타입에 따라 **라벨이 연속형이면 회귀** 알고리즘, 라벨이 **범주형이면 분류 알고리즘**으로 구분함.
- 대표 알고리즘. 
## 분류 VS 회귀
범주형 : 분류
연속형 : 회귀

### 비지도 학습(Unsupervised Learning)
* 라벨이 없는 훈련용 데이터에서 특징 변수들 간의 관계나 유사성을 기반으로 의미 있는 패턴을 추출.
- **자율학습**이라고도 함.
- **군집화, 차원축소, 추천시스템 등에 활용**됨.
* 대표 알고리즘 


1. 군집화(clustering)
2. 차원축소(dimension reduction)
3. 추천시스템(recommendation)
어떤 사람이 책을 읽을 때 추천해주는 시스템 
A와 B가 같은 책을 읽었을 때 A,B는 같은 취향을 가지고 있다고 보고 A가 본 것을 B에게 추천하는 시스템.

====================
## 강화학습
#### 행동하는 주체가 있고 행동을 했을 때의 상태와 보상을 바꿔주는 환경으로 구성됨 
#### 주체가 매번 어떠한 행동을 하면 환경에 의해 상태와 보상이 바뀌면서 주체는 보상이 가장 커지는 방향으로 계속 학습해 나가게 됨. 
대표 알고리즘: SARSA, Q-learning

요약 : **지도학습은 X, Y 존재 비지도 학습은 X만 존재**



==================
# 24차시 머신러닝 모델의 검증 및 평가
==================


=================
# 34차시 규제가 있는 선형회귀 모델(Ridge, Lasso, Elasic Net)
=================

## 규제가 있는 선형회귀모델 
### 파라미터가 너무 커지지 않도록 규제하는 추정법.

### 선형회귀모델의 규제 
- 모형의 과대적합을 막기 위한 규제방법으로 선형회귀모형에서는 보통 모델의 가중치를 제한하는 방법을 사용함.

### Ridge Regression 
**비용함수를 최소로하는 회귀계수를 찾는 문제다.** 

### Lasso Regression
**패널티가 다르다. 비용 함수에 규제항이 추가된 선형회귀모형이다.**
L1 규제를 추가함. 

### 릿지회귀와 라쏘회귀의 특징
- 두 방식 모두 추정치는 일반 선형회귀모형과는 달리, 편의가 발생하지만 분산은 더 작아지게 됨.
- 라쏘회귀의 경우 제약범쥐가 각진형태.
- 릿지회귀의 경우 제약 범위가 원의 형태.
두 방식 모두 편의가 발생. 

# 