================
# 2022 - 03 - 30
==============

# 자연어 생성 소개 
- 읽기 듣기,
- 자연어 텍스트 - > 정보
    - 예) 감성 분석 
        - 자연어 문장에 나타난 긍/부정의 감성을 분류하거나 점수로 매김


======
## 규칙기반 자연어 생성
- 자연어 생성을 여러 단계로 분할 
    - 예) 일기예보: 데이터에서 예보에 포함시킬 부분 선택 - > 강조할 부분과 언급만할 부분으로 나눔 - > 표현 방법을 결졍(전국적으로할지 지역별로 이야기할지,) - > 문장으로 표현 

- 각 단계에 적용될 규칙을 프로그래밍, 단계적으로 자연어를 생성

- 장점: 자연어 생성의 각 과정을 세세하게 제어할 수 있음
- 단점: 개발에 많은 노력필요, 자연스러운 문장을 생성하기 어려움. 

=======
## 기계학습을 이용한 자연어 생성 
- 기존의 자연어 문장을 학습시켜 새로운 문장을 생성
- 단계를 나누지 않고 종단간(end-to-end:처음부터 끝까지)구현이 가능
    - 기존의 날씨 데이터와 일기예보 텍스트를 수집해서 날씨 데이터를 X로 입력하면 일기예보 텍스트가 y로 출력되도록 함

- 장점: 자연스러운 표현 가능
- 단점: 많은 데이터가 필요. 제어가 어려움


========
## 규칙과학습의 혼합
- 규칙기반의 시스템은 연구가 많이 되어 최근의 연구는 기계학습이 주류이다.
- 기계학습만으로 현실적인 솔루션 개발은 어려움( 데이터의 부족, 제어문제 등 )
- 실제 솔루션 개발은 혼합적으로 이뤄지는 경우가 많음 




========
## 자연어 생성의 분야들 : 규칙과 학습의 혼합 
- 입력(X)의 형식에 따라 구분할 수 있음
- data-to-text: 기사/보고서 생성
- text_to_text: 기계 번역, 챗봇, 요약
- image-to-text: 캡션 생성
- 이야기 생성 


==========
## 기계학습을 통한 자연어 생성 기본 흐름 
- 데이터 수집
- 전처리 (토큰화 등 )
- 모형 개발 및 학습: 언어 모형
- 생성 (디코딩 )


===========
# 모아쓰기와 풀어쓰기

==========
# 글자수준 토큰화 
## 토큰화 tokenization
- 자연어 처리를 위해 문장을 처리 단위인 토큰으로 분리하는 것 
- 토큰화의 단위:
    - 글자
    - 준단어
    - 형태소
    - 단어 

===========
## 글자 수준 토큰화

- 글자 단위로 나누어 토큰화 하는 것
- 미등록 어휘(out-of-vocabulary:oov)문제가 없음
- 텍스트에서 의미나 문법적 측면을 무시하고 잘게 나누므로 처리가 어려움

==========
## 한국어 글자 수준 토큰화 
- 한글에는 모아쓰기(예:밝)와 풀어쓰기(예:ㅂㅏㄺ)가 있음
- 현대 한국어 모아쓰기 글자 수 : 11,172
- 현대 한국어 풀어쓰기 글자 수 :
    - 초성 19글자
    - 중성 21글자
    - 종성 28글자(종성없음도 1글자로 포함할 경우.)
- 한국어 모아쓰기 <-> 풀어쓰기 간 변환 : 유니코드 정규화를 이용하여 간단히 할 수 있음. 

========
# 유니코드 정규화 Unicode

- 문자표기를 위한 국제 표준
- 한글, 로마자 등 154종의 스크립트
- 143,859개의 글자.(현재도 추가되고 있음.)

========
## normalization 정규화 
- 동등한 문자들을 다루는 방법
- NFD:
    - 풀어쓰기(decomposition)
    - MAC에서 기본 사용
- NFC:
    - 모아쓰기(composition)
    - windows, Linux에서 기본 사용
=> **내부 처리 과정이므로 일반 사용자에게는 동일하게 보여야함**

